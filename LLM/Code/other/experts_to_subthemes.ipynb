{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE DIRECTORIES\n",
    "\n",
    "# Define the project root directory\n",
    "root_dir = '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/'\n",
    "\n",
    "# File paths\n",
    "target_data_dir  = '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data'\n",
    "\n",
    "# Define absolute python path\n",
    "sys.path.insert(0, root_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT FUNCTIONS & DATA\n",
    "\n",
    "# Load API and import request function\n",
    "from Code.API import get_chat_response, num_tokens_from_string\n",
    "\n",
    "# Import target data (target_code + target_content)\n",
    "target_data_250 = pd.read_csv(f'{target_data_dir}/targets_data_250.csv', sep=\";\")  #extensive target list from target_NACE_classification.xlsx\n",
    "target_data_150 = pd.read_csv(f'{target_data_dir}/targets_data_150.csv', sep=\";\")  #target list as in report 1 + assessments\n",
    "\n",
    "# Import list of experts\n",
    "from Data.REPORT_1.experts_report1 import experts_report1_list\n",
    "\n",
    "# Import a list of the thematic areas, and a list of sub-themes determined manually in Obsidian Canvases (building up on sub-themes used in report 1), that are not yet sorted per TA\n",
    "from Data.subthemes import subthemes_perTA_list,thematic_areas\n",
    "\n",
    "# List of TA codes (used later for the loop)\n",
    "TA = (['TA1','TA2','TA3','TA4','TA5','TA6','TA7']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE LLM PARAMETERS\n",
    "\n",
    "target_data = target_data_250\n",
    "seed = None\n",
    "temperature = 0.1\n",
    "model = \"llama-3.3-70b-instruct\" \n",
    "date = '0408'\n",
    "output_dir = f'/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/Outputs/{date}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE ANSWERS\n",
    "\n",
    "\n",
    "# (Loop tools)\n",
    "os.makedirs(output_dir, exist_ok=True) # Create the 'date' folder if it doesn't exist\n",
    "answers_content = []\n",
    "answers_metadata = pd.DataFrame(columns=[\"TA\",          # create empty panda dataframe with the following columns so to gather a bit more data on the responses and ultimately try to assess consistency\n",
    "                                         \"seed\",\n",
    "                                         \"temperature\",\n",
    "                                         \"system_fingerprint\", \n",
    "                                         \"prompt_tokens\", \n",
    "                                         \"completion_tokens\"])  \n",
    "\n",
    "# Loop\n",
    "for x in range(len(TA)):\n",
    "#for x in list([5,6]):\n",
    "\n",
    "    # Split the data per TA\n",
    "    target_subset = target_data[target_data['target_code'].str.contains(TA[x])]  # subset rows containing one of the characters in  TA[] (ie, select only a specific TA and its targets, because selecting everything in one go is too big for the AI to process)                                                                                                                                          # eg: TA[0] = 'TA1'\n",
    "    target_list = [f\"{row['target_code']}: {row['target_content']}\" for index, row in target_subset.iterrows()] # Concatenate target_code and target_content into a list so that it can be added to the prompt as text\n",
    "    \n",
    "    \n",
    "    # Define request\n",
    "    prompt = f'''\n",
    "            Data input & Context:\n",
    "            - Thematic area (TA): {thematic_areas[TA[x]]}\n",
    "            - List of European Green Deal (EGD) targets: {target_list}.\n",
    "            - List of sub-themes: {subthemes_perTA_list[TA[x]]}.\n",
    "            - List of experts: {experts_report1_list[TA[x]]}.\n",
    "\n",
    "            Task: \n",
    "            - For each subtheme, assign the best fitting experts based on their specialisation and the content of the targets of each subtheme.\n",
    "\n",
    "            Answer format: provide your answer as a table in csv format (separator: \";\"), with the following columns:\n",
    "            - thematic_area\n",
    "            - sub_theme \n",
    "            - experts (i.e., list of the most fitting expert names, maximum 3 experts per sub-theme)\n",
    "            - justification\n",
    "\n",
    "            Specifications:\n",
    "            - For each subtheme, write 1-2 sentences to justify why one or more specific experts were assigned to a specific sub-theme.\n",
    "            - Output only the CSV table. Do not include additional commentary.\n",
    "            \n",
    "            '''\n",
    "    \n",
    "\n",
    "    # Print pre-generation metadata (to double check amount of tokens in prompt, JRC llama3.3 should have a max of 120k)\n",
    "    prompt_metadata = f'''{TA[x]}:  \\nPrompt length: {len(prompt)} \\nPrompt tokens (o200k_base encoding): {num_tokens_from_string(prompt, \"o200k_base\")} \\nPrompt tokens (cl100k_base encoding): {num_tokens_from_string(prompt, \"cl100k_base\")} \\n'''\n",
    "    print(prompt_metadata)\n",
    "\n",
    "    # Generate answer\n",
    "    answer= get_chat_response(prompt=prompt,\n",
    "                              seed=seed,\n",
    "                              model=model,\n",
    "                              temperature=temperature  # The temperature parameter influences the randomness of the generated responses. A higher value, such as 0.8, makes the answers more diverse, while a lower value, like 0.2, makes them more focused and deterministic.\n",
    "                              )\n",
    "    # Print post-generation metadata \n",
    "    print(f'Answer generated.\\n')\n",
    "    print(f'Prompt tokens: {answer[\"prompt_tokens\"]} \\nCompletion tokens: {answer[\"completion_tokens\"]}')\n",
    "\n",
    "\n",
    "    answers_metadata.loc[x] = (f'{TA[x]}', #TA code\n",
    "                               seed, \n",
    "                               temperature, \n",
    "                               answer[\"system_fingerprint\"],\n",
    "                               answer[\"prompt_tokens\"],\n",
    "                               answer[\"completion_tokens\"]\n",
    "                               ) \n",
    "    \n",
    "    # Save response as csv file\n",
    "    output_name = f'{date}_experts_to_subthemes_{TA[x]}.csv'\n",
    "\n",
    "    with open((os.path.join(output_dir, output_name)), 'w') as f:\n",
    "         f.write(answer[\"response_content\"])\n",
    "\n",
    "\n",
    "# Save triplicats metadata as csv\n",
    "answers_metadata.to_csv(path_or_buf= f'/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/Outputs/{date}/{date}output_s{seed}_t{temperature}_metadata.csv', \n",
    "                        sep=';', \n",
    "                        index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS AGGREGATION\n",
    "\n",
    "\n",
    "# (If necessary, re-specify the directory path and file pattern)\n",
    "date = date\n",
    "output_dir = output_dir\n",
    "file_pattern = f'{date}_experts_to_subthemes_*.csv' # pattern to match all files generated in the current session\n",
    "\n",
    "csv_files = glob.glob(output_dir + '/' + file_pattern) # Get a list of all CSV files matching the pattern\n",
    "\n",
    "# Initialize an empty list to store the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over each CSV file, read it into a dataframe, and append to the list\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, on_bad_lines='skip', sep=';')\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "if dataframes:\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "else:\n",
    "    print(\"No dataframes to concatenate.\")\n",
    "\n",
    "# Write the combined dataframe to a new CSV file\n",
    "combined_df.to_csv(f'{output_dir}{date}_network_aggregated.csv', index=True, sep=';')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
