{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pdfplumber\n",
    "import docx2txt\n",
    "\n",
    "\n",
    "# Define absolute python path\n",
    "sys.path.insert(0, '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/') \n",
    "\n",
    "\n",
    "## FUNCTIONS\n",
    "\n",
    "# Load API and import request function\n",
    "from Code.API import get_chat_response, num_tokens_from_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "\n",
    "target_data_directory = '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data'\n",
    "report1_directory = '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/REPORT_1/report1_trimmed.pdf'\n",
    "report2_directory = '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/REPORT_2/access_20250310'\n",
    "\n",
    "# Import all target data (target_code + target_content)\n",
    "target_data_250 = pd.read_csv(f'{target_data_directory}/targets_data_250.csv', sep=\";\")  #extensive target list from target_NACE_classification.xlsx\n",
    "target_data_150 = pd.read_csv(f'{target_data_directory}/targets_data_150.csv', sep=\";\")  #target list as in report 1\n",
    "\n",
    "\n",
    "# Import & parse report1\n",
    "with pdfplumber.open(report1_directory) as pdf:\n",
    "    # Extract the text from the PDF\n",
    "    report1 = \"\"\n",
    "    for page in pdf.pages:\n",
    "        report1 += page.extract_text()\n",
    "\n",
    "# Clean-up report1\n",
    "report1 = report1.strip() \n",
    "report1 = report1.replace(\"\\n\", \" \")\n",
    "report1 = report1.replace(\"\\t\", \" \")\n",
    "\n",
    "# Import & parse report2\n",
    "\n",
    "# create a dictionary to access different chapters of report2   \n",
    "report2 = { \n",
    "    'chapter1': docx2txt.process(f'{report2_directory}/NEW_Chapter1_CLEAN - Introduction & setting the scene_LM_trimmed.docx'),\n",
    "    'chapter2': docx2txt.process(f'{report2_directory}/NEW_Chapter2 (ex chp3) - Environmental impacts_ZOTERO_trimmed.docx'),\n",
    "    'chapter3': docx2txt.process(f'{report2_directory}/NEW_Chapter3 (ex chp4) with BIBLIO - Challenges and enablers for EGD objectives_trimmed.docx'),\n",
    "    'chapter4': docx2txt.process(f'{report2_directory}/NEW_Chapter4 (ex chp5) - Enabling the green transition_trimmed.docx'),\n",
    "    'chapter5': docx2txt.process(f'{report2_directory}/NEW_Chapter5 - Fair and just transition_trimmed.docx'),\n",
    "    'chapter6': docx2txt.process(f'{report2_directory}/NEW_Chapter6 - Financing the green transition.docx')\n",
    "}\n",
    "\n",
    "# clean up report2 chapters\n",
    "for chapter, text in report2.items():\n",
    "    report2[chapter] = text.strip()\n",
    "    report2[chapter] = report2[chapter].replace(\"\\n\", \" \")\n",
    "    report2[chapter] = report2[chapter].replace(\"\\t\", \" \")\n",
    "\n",
    "\n",
    "\n",
    "subthemes_list = {\n",
    "    'TA1': [\n",
    "        \"Climate Resilience\",\n",
    "        \"GHG Reduction\",\n",
    "        \"GHG Reduction - Buildings\",\n",
    "        \"GHG Reduction - Transports\"\n",
    "        \"GHG Removal\",\n",
    "    ],\n",
    "    'TA2': [\n",
    "        \"Renewable Energy\",\n",
    "        \"Renewable Energy - Heating & Cooling\",\n",
    "        \"Renewable Energy - Hydrogen Production\",\n",
    "        \"Renewable Energy - Ocean/Offshore\",\n",
    "        \"Renewable Energy - Solar\",\n",
    "        \"Energy Efficiency\",\n",
    "        \"Energy Efficiency - Buildings\",\n",
    "        \"Energy Infrastructure\",\n",
    "        \"Social Security - Energy\",\n",
    "    ],\n",
    "    'TA3': [\n",
    "        \t\"Waste Reduction\",\n",
    "          \"Waste Reduction - Municipal Waste\",\n",
    "          \"Waste Reduction - Food Waste\",\n",
    "          \"Waste Reduction - Plastic & Packaging\",\n",
    "          \"Circularity/Recycling\",\n",
    "          \"Circularity/Recycling - Municipal Waste\",\n",
    "          \"Circularity/Recycling - Textile Waste\",\n",
    "          \"Circularity/Recycling - Plastic & Packaging\",\n",
    "          \"Circularity/Recycling - Plastic & Packaging - Bio-based plastics\",\n",
    "          \"Circularity/Recycling - Vehicle Circularity\",\n",
    "          \"Circularity/Recycling - Critical Raw Materials - Batteries Recycling\",\n",
    "          \"Critical Raw Materials - Extraction & Import\",\n",
    "          \"Net-Zero Technology - Manufacturing\",\n",
    "    ],\n",
    "    'TA4': [\n",
    "        \t\"Rail\",\n",
    "          \"Net-Zero Technology - Road Vehicles\",\n",
    "          \"Net-Zero Technology - Maritime Transport\",\n",
    "          \"Net-Zero Technology - Aviation\",\n",
    "          \"Biofuels\",\n",
    "          \"Other Low-Carbon Fuels\",\n",
    "          \"Hydrogen Distribution\",\n",
    "          \"Urban Mobility\",\n",
    "          \"Transport Logistics\",\n",
    "    ],\n",
    "    'TA5': [\n",
    "        \t\"Food quality\",\n",
    "          \"Food quality - Animal Welfare\",\n",
    "          \"Food quality - Healthy Food\",\n",
    "          \"Food affordability\",\n",
    "          \"Pesticides Reduction\",\n",
    "          \"Competitive Agriculture\",\n",
    "          \"Social Security - Workers Protection\",\n",
    "    ],\n",
    "    'TA6': [\n",
    "        \t\"Terrestrial Ecosystems Restoration\",\n",
    "          \"Terrestrial Ecosystems Restoration - Rivers\",\n",
    "          \"Terrestrial Ecosystems Restoration - Agricultural Ecosystems\",\n",
    "          \"Terrestrial Ecosystems Restoration - Forests\",\n",
    "          \"Marine Ecosystem Restoration\",\n",
    "          \"Biodiversity Protection & Conservation\",\n",
    "          \"Biodiversity Protection & Conservation - Fisheries\",\n",
    "          \"Biodiversity Protection & Conservation - Monitoring\",\n",
    "          \"Biodiversity Protection & Conservation - Urban Nature\",\n",
    "    ],\n",
    "    'TA7': [\n",
    "        \"Forest Bioeconomy\",\n",
    "        \"Improve Air Quality\",\n",
    "        \"Improve Water Quality\",\n",
    "        \"Improve Soils Health\",\n",
    "        \"Noise Reduction\",\n",
    "        \"Social Security - Sanitation\"\n",
    "          ],\n",
    "}\n",
    "\n",
    "\n",
    "impact_weight_meanings = {     # in json object format so that the LLM can most efficiently understand its structure, based on Nilssen et al. (2016)\n",
    "  \"weights\": [\n",
    "    {\n",
    "      \"weight\": \"+3\",\n",
    "      \"name\": \"Indivisible\",\n",
    "      \"explanation\": \"Inextricably linked to the achievement of another target.\",\n",
    "      \"example\": \"Ending all forms of discrimination against women and girls is indivisible from ensuring women’s full and effective participation and equal opportunities for leadership.\"\n",
    "    },\n",
    "    {\n",
    "      \"weight\": \"+2\",\n",
    "      \"name\": \"Reinforcing\",\n",
    "      \"explanation\": \"Aids the achievement of another target.\",\n",
    "      \"example\": \"Providing access to electricity reinforces water‐pumping and irrigation systems. Strengthening the capacity to adapt to climate‐related hazards reduces losses caused by disasters.\"\n",
    "    },\n",
    "    {\n",
    "      \"weight\": \"+1\",\n",
    "      \"name\": \"Enabling\",\n",
    "      \"explanation\": \"Creates conditions that further another target.\",\n",
    "      \"example\": \"Providing electricity access in rural homes enables education, because it makes it possible to do homework at night with electric lighting.\"\n",
    "    },\n",
    "    {\n",
    "      \"weight\": \"-1\",\n",
    "      \"name\": \"Constraining\",\n",
    "      \"explanation\": \"Limits options on another target.\",\n",
    "      \"example\": \"Improved water efficiency can constrain agricultural irrigation. Reducing climate change can constrain the options for energy access.\"\n",
    "    },\n",
    "    {\n",
    "      \"weight\": \"-2\",\n",
    "      \"name\": \"Counteracting\",\n",
    "      \"explanation\": \"Clashes with another target.\",\n",
    "      \"example\": \"Boosting consumption for growth can counteract waste reduction and climate mitigation.\"\n",
    "    },\n",
    "    {\n",
    "      \"weight\": \"-3\",\n",
    "      \"name\": \"Cancelling\",\n",
    "      \"explanation\": \"Makes it impossible to reach another goal.\",\n",
    "      \"example\": \"Fully ensuring public transparency and democratic accountability cannot be combined with national‐security goals. Full protection of natural reserves excludes public access for recreation.\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and store all target data into one dictionary\n",
    "\n",
    "# Final structure: 'target_data_dict' / thematic_area_code / sub_theme / ta_code | ta_content | ta_assessment\n",
    "\n",
    "\n",
    "# Indicate the main dataset to work with\n",
    "data = target_data_250\n",
    "\n",
    "# 1) Create a first sub-dictionary to store the subthemes and their respective target data\n",
    "subthemes_dict = {}\n",
    "\n",
    "# Iterate over the unique 'sub_theme' values\n",
    "for theme in data['sub_theme'].unique():\n",
    "    # Filter the DataFrame for the current 'sub_theme'\n",
    "    theme_df = data[data['sub_theme'] == theme][['target_code', 'target_content', 'target_assessment']]\n",
    "    # Add the filtered DataFrame to the dictionary\n",
    "    subthemes_dict[theme] = theme_df\n",
    "\n",
    "# 2) Create the final overarching dictionary and sort into it the sub-themes and their target data per thematic areas\n",
    "target_data_dict = {}\n",
    "\n",
    "# Iterate over the unique 'thematic_area_code' values\n",
    "for ta in data['thematic_area_code'].unique():\n",
    "    # Initialize the thematic area in the dictionary\n",
    "    target_data_dict[ta] = {}\n",
    "    \n",
    "    # Iterate over the unique 'sub_theme' values for the current thematic area\n",
    "    for theme in data[data['thematic_area_code'] == ta]['sub_theme'].unique():\n",
    "        theme_df = subthemes_dict[theme] # Get the sub-theme DataFrame from the subthemes_dict\n",
    "        target_data_dict[ta][theme] = theme_df # Add the sub-theme DataFrame to the target_data_150_dict\n",
    "\n",
    "\n",
    "#print(target_data_dict['TA3']['Circularity/Recycling - Vehicle Circularity']) # example of how to access a specific sub-theme in the dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all potential pairs of thematic areas (2x21= 42 pairs)\n",
    "ta_pairs = {} # dictionary to store all thematic area pairs\n",
    "ta_list = ['TA1', 'TA2', 'TA3', 'TA4', 'TA5', 'TA6', 'TA7'] # list of thematic areas\n",
    "pair_id = 0 \n",
    "\n",
    "for i in range(len(ta_list)):\n",
    "    for j in range(len(ta_list)):\n",
    "        if i != j:\n",
    "            ta_pairs[pair_id] = [ta_list[i], ta_list[j]] \n",
    "            pair_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA_pair: 0 - ['TA1', 'TA2'] \n",
      "Prompt length: 403387 \n",
      "Prompt tokens (o200k_base encoding): 76669 \n",
      "Prompt tokens (cl100k_base encoding): 77230 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 77223 \n",
      "Completion tokens: 534\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 1 - ['TA1', 'TA3'] \n",
      "Prompt length: 405158 \n",
      "Prompt tokens (o200k_base encoding): 77024 \n",
      "Prompt tokens (cl100k_base encoding): 77571 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 77564 \n",
      "Completion tokens: 773\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 2 - ['TA1', 'TA4'] \n",
      "Prompt length: 409722 \n",
      "Prompt tokens (o200k_base encoding): 78122 \n",
      "Prompt tokens (cl100k_base encoding): 78646 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 78639 \n",
      "Completion tokens: 568\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 3 - ['TA1', 'TA5'] \n",
      "Prompt length: 412767 \n",
      "Prompt tokens (o200k_base encoding): 78744 \n",
      "Prompt tokens (cl100k_base encoding): 79277 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79270 \n",
      "Completion tokens: 411\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 4 - ['TA1', 'TA6'] \n",
      "Prompt length: 406199 \n",
      "Prompt tokens (o200k_base encoding): 77256 \n",
      "Prompt tokens (cl100k_base encoding): 77810 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 77803 \n",
      "Completion tokens: 609\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 5 - ['TA1', 'TA7'] \n",
      "Prompt length: 406149 \n",
      "Prompt tokens (o200k_base encoding): 77211 \n",
      "Prompt tokens (cl100k_base encoding): 77733 \n",
      "\n",
      "An error occurred: Error code: 429 - {'detail': 'You have exceeded the rate limit for requests. Please, retry later.'}\n",
      "Answer generated.\n",
      "An error occurred (TypeError): 'NoneType' object is not subscriptable. Retrying (1/5)\n",
      "TA_pair: 5 - ['TA1', 'TA7'] \n",
      "Prompt length: 406149 \n",
      "Prompt tokens (o200k_base encoding): 77211 \n",
      "Prompt tokens (cl100k_base encoding): 77733 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 77726 \n",
      "Completion tokens: 663\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 6 - ['TA2', 'TA1'] \n",
      "Prompt length: 403387 \n",
      "Prompt tokens (o200k_base encoding): 76669 \n",
      "Prompt tokens (cl100k_base encoding): 77230 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 77223 \n",
      "Completion tokens: 625\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 7 - ['TA2', 'TA3'] \n",
      "Prompt length: 409296 \n",
      "Prompt tokens (o200k_base encoding): 78033 \n",
      "Prompt tokens (cl100k_base encoding): 78610 \n",
      "\n",
      "An error occurred: Error code: 429 - {'detail': 'You have exceeded the rate limit for requests. Please, retry later.'}\n",
      "Answer generated.\n",
      "An error occurred (TypeError): 'NoneType' object is not subscriptable. Retrying (1/5)\n",
      "TA_pair: 7 - ['TA2', 'TA3'] \n",
      "Prompt length: 409296 \n",
      "Prompt tokens (o200k_base encoding): 78033 \n",
      "Prompt tokens (cl100k_base encoding): 78610 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 78603 \n",
      "Completion tokens: 689\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 8 - ['TA2', 'TA4'] \n",
      "Prompt length: 413860 \n",
      "Prompt tokens (o200k_base encoding): 79131 \n",
      "Prompt tokens (cl100k_base encoding): 79685 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79678 \n",
      "Completion tokens: 1024\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 9 - ['TA2', 'TA5'] \n",
      "Prompt length: 416905 \n",
      "Prompt tokens (o200k_base encoding): 79753 \n",
      "Prompt tokens (cl100k_base encoding): 80316 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80309 \n",
      "Completion tokens: 637\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 10 - ['TA2', 'TA6'] \n",
      "Prompt length: 410337 \n",
      "Prompt tokens (o200k_base encoding): 78265 \n",
      "Prompt tokens (cl100k_base encoding): 78849 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 78842 \n",
      "Completion tokens: 607\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 11 - ['TA2', 'TA7'] \n",
      "Prompt length: 410287 \n",
      "Prompt tokens (o200k_base encoding): 78220 \n",
      "Prompt tokens (cl100k_base encoding): 78772 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 78765 \n",
      "Completion tokens: 752\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 12 - ['TA3', 'TA1'] \n",
      "Prompt length: 405158 \n",
      "Prompt tokens (o200k_base encoding): 77024 \n",
      "Prompt tokens (cl100k_base encoding): 77571 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 77564 \n",
      "Completion tokens: 764\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 13 - ['TA3', 'TA2'] \n",
      "Prompt length: 409296 \n",
      "Prompt tokens (o200k_base encoding): 78033 \n",
      "Prompt tokens (cl100k_base encoding): 78610 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 78603 \n",
      "Completion tokens: 771\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 14 - ['TA3', 'TA4'] \n",
      "Prompt length: 415631 \n",
      "Prompt tokens (o200k_base encoding): 79486 \n",
      "Prompt tokens (cl100k_base encoding): 80026 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80019 \n",
      "Completion tokens: 521\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 15 - ['TA3', 'TA5'] \n",
      "Prompt length: 418676 \n",
      "Prompt tokens (o200k_base encoding): 80108 \n",
      "Prompt tokens (cl100k_base encoding): 80657 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80650 \n",
      "Completion tokens: 727\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 16 - ['TA3', 'TA6'] \n",
      "Prompt length: 412108 \n",
      "Prompt tokens (o200k_base encoding): 78620 \n",
      "Prompt tokens (cl100k_base encoding): 79190 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79183 \n",
      "Completion tokens: 759\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 17 - ['TA3', 'TA7'] \n",
      "Prompt length: 412058 \n",
      "Prompt tokens (o200k_base encoding): 78575 \n",
      "Prompt tokens (cl100k_base encoding): 79113 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79106 \n",
      "Completion tokens: 714\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 18 - ['TA4', 'TA1'] \n",
      "Prompt length: 409722 \n",
      "Prompt tokens (o200k_base encoding): 78122 \n",
      "Prompt tokens (cl100k_base encoding): 78646 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 78639 \n",
      "Completion tokens: 974\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 19 - ['TA4', 'TA2'] \n",
      "Prompt length: 413860 \n",
      "Prompt tokens (o200k_base encoding): 79131 \n",
      "Prompt tokens (cl100k_base encoding): 79685 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79678 \n",
      "Completion tokens: 667\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 20 - ['TA4', 'TA3'] \n",
      "Prompt length: 415631 \n",
      "Prompt tokens (o200k_base encoding): 79486 \n",
      "Prompt tokens (cl100k_base encoding): 80026 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80019 \n",
      "Completion tokens: 873\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 21 - ['TA4', 'TA5'] \n",
      "Prompt length: 423240 \n",
      "Prompt tokens (o200k_base encoding): 81206 \n",
      "Prompt tokens (cl100k_base encoding): 81732 \n",
      "\n",
      "An error occurred: Error code: 429 - {'detail': 'You have exceeded the rate limit for requests. Please, retry later.'}\n",
      "Answer generated.\n",
      "An error occurred (TypeError): 'NoneType' object is not subscriptable. Retrying (1/5)\n",
      "TA_pair: 21 - ['TA4', 'TA5'] \n",
      "Prompt length: 423240 \n",
      "Prompt tokens (o200k_base encoding): 81206 \n",
      "Prompt tokens (cl100k_base encoding): 81732 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 81725 \n",
      "Completion tokens: 782\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 22 - ['TA4', 'TA6'] \n",
      "Prompt length: 416672 \n",
      "Prompt tokens (o200k_base encoding): 79718 \n",
      "Prompt tokens (cl100k_base encoding): 80265 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80258 \n",
      "Completion tokens: 753\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 23 - ['TA4', 'TA7'] \n",
      "Prompt length: 416622 \n",
      "Prompt tokens (o200k_base encoding): 79673 \n",
      "Prompt tokens (cl100k_base encoding): 80188 \n",
      "\n",
      "An error occurred: Error code: 429 - {'detail': 'You have exceeded the rate limit for requests. Please, retry later.'}\n",
      "Answer generated.\n",
      "An error occurred (TypeError): 'NoneType' object is not subscriptable. Retrying (1/5)\n",
      "TA_pair: 23 - ['TA4', 'TA7'] \n",
      "Prompt length: 416622 \n",
      "Prompt tokens (o200k_base encoding): 79673 \n",
      "Prompt tokens (cl100k_base encoding): 80188 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80181 \n",
      "Completion tokens: 862\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 24 - ['TA5', 'TA1'] \n",
      "Prompt length: 412767 \n",
      "Prompt tokens (o200k_base encoding): 78744 \n",
      "Prompt tokens (cl100k_base encoding): 79277 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79270 \n",
      "Completion tokens: 677\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 25 - ['TA5', 'TA2'] \n",
      "Prompt length: 416905 \n",
      "Prompt tokens (o200k_base encoding): 79753 \n",
      "Prompt tokens (cl100k_base encoding): 80316 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80309 \n",
      "Completion tokens: 620\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 26 - ['TA5', 'TA3'] \n",
      "Prompt length: 418676 \n",
      "Prompt tokens (o200k_base encoding): 80108 \n",
      "Prompt tokens (cl100k_base encoding): 80657 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80650 \n",
      "Completion tokens: 482\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 27 - ['TA5', 'TA4'] \n",
      "Prompt length: 423240 \n",
      "Prompt tokens (o200k_base encoding): 81206 \n",
      "Prompt tokens (cl100k_base encoding): 81732 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 81725 \n",
      "Completion tokens: 436\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 28 - ['TA5', 'TA6'] \n",
      "Prompt length: 419717 \n",
      "Prompt tokens (o200k_base encoding): 80340 \n",
      "Prompt tokens (cl100k_base encoding): 80896 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80889 \n",
      "Completion tokens: 507\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 29 - ['TA5', 'TA7'] \n",
      "Prompt length: 419667 \n",
      "Prompt tokens (o200k_base encoding): 80295 \n",
      "Prompt tokens (cl100k_base encoding): 80819 \n",
      "\n",
      "An error occurred: Error code: 429 - {'detail': 'You have exceeded the rate limit for requests. Please, retry later.'}\n",
      "Answer generated.\n",
      "An error occurred (TypeError): 'NoneType' object is not subscriptable. Retrying (1/5)\n",
      "TA_pair: 29 - ['TA5', 'TA7'] \n",
      "Prompt length: 419667 \n",
      "Prompt tokens (o200k_base encoding): 80295 \n",
      "Prompt tokens (cl100k_base encoding): 80819 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80812 \n",
      "Completion tokens: 472\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 30 - ['TA6', 'TA1'] \n",
      "Prompt length: 406199 \n",
      "Prompt tokens (o200k_base encoding): 77256 \n",
      "Prompt tokens (cl100k_base encoding): 77810 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 77803 \n",
      "Completion tokens: 783\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 31 - ['TA6', 'TA2'] \n",
      "Prompt length: 410337 \n",
      "Prompt tokens (o200k_base encoding): 78265 \n",
      "Prompt tokens (cl100k_base encoding): 78849 \n",
      "\n",
      "An error occurred: Error code: 429 - {'detail': 'You have exceeded the rate limit for requests. Please, retry later.'}\n",
      "Answer generated.\n",
      "An error occurred (TypeError): 'NoneType' object is not subscriptable. Retrying (1/5)\n",
      "TA_pair: 31 - ['TA6', 'TA2'] \n",
      "Prompt length: 410337 \n",
      "Prompt tokens (o200k_base encoding): 78265 \n",
      "Prompt tokens (cl100k_base encoding): 78849 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 78842 \n",
      "Completion tokens: 1421\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 32 - ['TA6', 'TA3'] \n",
      "Prompt length: 412108 \n",
      "Prompt tokens (o200k_base encoding): 78620 \n",
      "Prompt tokens (cl100k_base encoding): 79190 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79183 \n",
      "Completion tokens: 884\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 33 - ['TA6', 'TA4'] \n",
      "Prompt length: 416672 \n",
      "Prompt tokens (o200k_base encoding): 79718 \n",
      "Prompt tokens (cl100k_base encoding): 80265 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80258 \n",
      "Completion tokens: 810\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 34 - ['TA6', 'TA5'] \n",
      "Prompt length: 419717 \n",
      "Prompt tokens (o200k_base encoding): 80340 \n",
      "Prompt tokens (cl100k_base encoding): 80896 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80889 \n",
      "Completion tokens: 809\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 35 - ['TA6', 'TA7'] \n",
      "Prompt length: 413099 \n",
      "Prompt tokens (o200k_base encoding): 78807 \n",
      "Prompt tokens (cl100k_base encoding): 79352 \n",
      "\n",
      "An error occurred: Error code: 429 - {'detail': 'You have exceeded the rate limit for requests. Please, retry later.'}\n",
      "Answer generated.\n",
      "An error occurred (TypeError): 'NoneType' object is not subscriptable. Retrying (1/5)\n",
      "TA_pair: 35 - ['TA6', 'TA7'] \n",
      "Prompt length: 413099 \n",
      "Prompt tokens (o200k_base encoding): 78807 \n",
      "Prompt tokens (cl100k_base encoding): 79352 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79345 \n",
      "Completion tokens: 1016\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 36 - ['TA7', 'TA1'] \n",
      "Prompt length: 406149 \n",
      "Prompt tokens (o200k_base encoding): 77211 \n",
      "Prompt tokens (cl100k_base encoding): 77733 \n",
      "\n",
      "An error occurred: Error code: 429 - {'detail': 'You have exceeded the rate limit for requests. Please, retry later.'}\n",
      "Answer generated.\n",
      "An error occurred (TypeError): 'NoneType' object is not subscriptable. Retrying (1/5)\n",
      "TA_pair: 36 - ['TA7', 'TA1'] \n",
      "Prompt length: 406149 \n",
      "Prompt tokens (o200k_base encoding): 77211 \n",
      "Prompt tokens (cl100k_base encoding): 77733 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 77726 \n",
      "Completion tokens: 831\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 37 - ['TA7', 'TA2'] \n",
      "Prompt length: 410287 \n",
      "Prompt tokens (o200k_base encoding): 78220 \n",
      "Prompt tokens (cl100k_base encoding): 78772 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 78765 \n",
      "Completion tokens: 566\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 38 - ['TA7', 'TA3'] \n",
      "Prompt length: 412058 \n",
      "Prompt tokens (o200k_base encoding): 78575 \n",
      "Prompt tokens (cl100k_base encoding): 79113 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79106 \n",
      "Completion tokens: 587\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 39 - ['TA7', 'TA4'] \n",
      "Prompt length: 416622 \n",
      "Prompt tokens (o200k_base encoding): 79673 \n",
      "Prompt tokens (cl100k_base encoding): 80188 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80181 \n",
      "Completion tokens: 1179\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 40 - ['TA7', 'TA5'] \n",
      "Prompt length: 419667 \n",
      "Prompt tokens (o200k_base encoding): 80295 \n",
      "Prompt tokens (cl100k_base encoding): 80819 \n",
      "\n",
      "An error occurred: Error code: 429 - {'detail': 'You have exceeded the rate limit for requests. Please, retry later.'}\n",
      "Answer generated.\n",
      "An error occurred (TypeError): 'NoneType' object is not subscriptable. Retrying (1/5)\n",
      "TA_pair: 40 - ['TA7', 'TA5'] \n",
      "Prompt length: 419667 \n",
      "Prompt tokens (o200k_base encoding): 80295 \n",
      "Prompt tokens (cl100k_base encoding): 80819 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 80812 \n",
      "Completion tokens: 634\n",
      "-- 1 min pause \n",
      "\n",
      "TA_pair: 41 - ['TA7', 'TA6'] \n",
      "Prompt length: 413099 \n",
      "Prompt tokens (o200k_base encoding): 78807 \n",
      "Prompt tokens (cl100k_base encoding): 79352 \n",
      "\n",
      "Answer generated.\n",
      "Prompt tokens: 79345 \n",
      "Completion tokens: 887\n",
      "-- 1 min pause \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GENERATE ANSWERS\n",
    "\n",
    "\n",
    "# Set parameters\n",
    "seed = None \n",
    "temperature = 0.1\n",
    "model = \"llama-3.3-70b-instruct\" #\"llama-3.3-70b-instruct\" \"gpt-4o\" \"nous-hermes-2-mixtral-8x7b-dpo\"\n",
    "date = '0328' \n",
    "output_directory = f'/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/Outputs/{date}/'\n",
    "os.makedirs(output_directory, exist_ok=True) # Create the 'date' folder if it doesn't exist\n",
    "\n",
    "\n",
    "\n",
    "# (loop tools and formatting)\n",
    "answers_metadata = pd.DataFrame(columns=[\"ta_pairs_nbr\",\n",
    "                                         \"ta_pairs_pairs\",        # create empty panda dataframe with the following columns so to gather a bit more data on the responses and ultimately try to assess consistency\n",
    "                                         \"model\",\n",
    "                                         \"seed\",\n",
    "                                         \"temperature\",\n",
    "                                         \"system_fingerprint\", \n",
    "                                         \"prompt_tokens\", \n",
    "                                         \"completion_tokens\"])  \n",
    "\n",
    "\n",
    "# Loop\n",
    "\n",
    "\n",
    "for x in range(len(ta_pairs)):\n",
    "#for x in range(8, 42):\n",
    "#for x in list([12,13,14]):\n",
    "\n",
    "    success = False  # Initialize a flag to track whether the operation was successful\n",
    "    retry_count = 0  # Initialize a counter to track the number of retries\n",
    "    max_retries = 5  # adjust this value to set the desired number of retries\n",
    "\n",
    "    while not success and retry_count < max_retries:\n",
    "        try:\n",
    "            # Subset data to avoid overloading the model\n",
    "            sub1 = [f\"{target_data_dict[ta_pairs[x][0]]}\"] # this will access the data stored in target_data_dict for the thematic_area_code stored in ta_pairs[x][0] (e.g., target_data_dict[ta_pairs[0][0]] <=> target_data_dict['TA1])\n",
    "            sub2 = [f\"{target_data_dict[ta_pairs[x][1]]}\"] # same thing here, but for the second element of the ta_pair[x]\n",
    "\n",
    "\n",
    "            # Define prompt\n",
    "            prompt = f'''\n",
    "                Data input & Context:\n",
    "                - List A: first list of European Green Deal (EGD) targets grouped by sub-themes:{sub1}.\n",
    "                - List B: second list of EGD targets grouped by sub-themes: {sub2}.\n",
    "                - Report n°2: [ {report2['chapter1']} + {report2['chapter2']} + {report2['chapter3']} + {report2['chapter4']} + {report2['chapter5']} ].\n",
    "\n",
    "                Task: \n",
    "                - Determine how and how much sub-themes in List A may positiviely or negatively influence sub-themes in List B (i.e., determine potential synergies and/or trade-offs).\n",
    "                - Take into account the context and information of Report n°2 as well as the information available about the targets in both lists.\n",
    "\n",
    "                Answer format: provide your answer as a table in csv format please (separator: \";\"), with the following columns:\n",
    "                - source_subtheme (e.g., GHG Reduction).\n",
    "                - source_subtheme_targets (e.g.,TA1.3,TA1.7,TA1.9,TA1.11,TA1.13,TA5.7) .\n",
    "                - impact_subtheme (the name of the subtheme that is likely to be positively or negatively affected by the implementation and requirements of the sub-theme in the 'source_subtheme' column).\n",
    "                - impact_type (positive '+' or negative '-').\n",
    "                - impact_weight (-3,-2,-1,1,2,3).\n",
    "                - justification.\n",
    "\n",
    "                Specifications:\n",
    "                - The impacts can have different weights, which have the following meanings: {impact_weight_meanings}\n",
    "                - Only the following sub-themes can be added to the table: {subthemes_list[ta_pairs[x][0]]} and {subthemes_list[ta_pairs[x][1]]}.\n",
    "                - This is crucial: do not invent new sub-themes.\n",
    "                - Connections can only be made from sub-themes in List A to sub-themes in List B, not the contrary.\n",
    "                - If some sub-themes do not have any connections at all (i.e., are isolated), do not add any row.\n",
    "                - One row per connection, if you deem that one sub-theme has an impact on multiple other sub-themes, add as many rows for a same sub-theme as necessary.\n",
    "                - It is critical that your analysis is based on the context of the report and not just on the semantics of the target contents.\n",
    "                - This is mandatory: for each sub-theme connection, write 1-2 concise sentences justifying your choice. \n",
    "                - Output only the CSV table. Do not include additional commentary.\n",
    "            '''\n",
    "\n",
    "            # Print pre-generation metadata (to double check amount of tokens in prompt, JRC llama3.3 should have a max of 120k)\n",
    "            prompt_metadata = f'''TA_pair: {x} - {ta_pairs[x]} \\nPrompt length: {len(prompt)} \\nPrompt tokens (o200k_base encoding): {num_tokens_from_string(prompt, \"o200k_base\")} \\nPrompt tokens (cl100k_base encoding): {num_tokens_from_string(prompt, \"cl100k_base\")} \\n'''\n",
    "            print(prompt_metadata)\n",
    "\n",
    "            # Generate answer\n",
    "            answer = get_chat_response(prompt=prompt,\n",
    "                                      seed=seed,\n",
    "                                      model=model,\n",
    "                                      temperature=temperature)\n",
    "\n",
    "            # Print post-generation metadata \n",
    "            print(f'Answer generated.')\n",
    "            print(f'Prompt tokens: {answer[\"prompt_tokens\"]} \\nCompletion tokens: {answer[\"completion_tokens\"]}')\n",
    "\n",
    "\n",
    "            # Add the metadata of the generated answer to a dataframe\n",
    "            answers_metadata.loc[x] = (x,\n",
    "                                       ta_pairs[x],\n",
    "                                       model,\n",
    "                                       seed,\n",
    "                                       temperature,\n",
    "                                       answer[\"system_fingerprint\"],\n",
    "                                       answer[\"prompt_tokens\"],\n",
    "                                       answer[\"completion_tokens\"])\n",
    "\n",
    "            # Save the generated answer as a CSV file\n",
    "            output_name = f'{date}_network_pair{x}.csv'\n",
    "\n",
    "            with open((os.path.join(output_directory, output_name)), 'w') as f:\n",
    "                f.write(answer[\"response_content\"])\n",
    "\n",
    "            # If success, set the success flag to True\n",
    "            success = True\n",
    "\n",
    "            # If success, add a 2-minute pause between answer requests to avoid RateLimitErrors\n",
    "            print(f\"-- 1 min pause \\n\")\n",
    "            time.sleep(60)\n",
    "\n",
    "        except Exception as e:\n",
    "            \n",
    "            retry_count += 1  # Increment the retry counter if an error occurs\n",
    "            error_type = type(e).__name__  # Get the type of error that occurred\n",
    "            error_message = str(e) # Get the error message\n",
    "            print(f\"An error occurred ({error_type}): {error_message}. Retrying ({retry_count}/{max_retries})\")  # Print an error message with the type and message\n",
    "\n",
    "\n",
    "    # Print a message if the operation failed after the maximum number of retries\n",
    "    if not success:\n",
    "        print(f\"Failed to generate answer for pair{x} ({ta_pairs[x]}) after {max_retries} retries.\")\n",
    "\n",
    "# Save the metadata dataframe as a CSV file\n",
    "answers_metadata.to_csv(path_or_buf=os.path.join(output_directory, f'{date}_network_metadata.csv'),\n",
    "                         sep=';',\n",
    "                         index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results chunks into a single file\n",
    "\n",
    "\n",
    "# Specify the directory path and file pattern\n",
    "date = date\n",
    "output_directory = f'/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/Outputs/{date}/'\n",
    "file_pattern = f'{date}_network_pair*.csv'\n",
    "\n",
    "# Get a list of all CSV files matching the pattern\n",
    "csv_files = glob.glob(output_directory + '/' + file_pattern)\n",
    "\n",
    "# Initialize an empty list to store the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over each CSV file, read it into a dataframe, and append to the list\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, on_bad_lines='skip', sep=';')\n",
    "        dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "if dataframes:\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "else:\n",
    "    print(\"No dataframes to concatenate.\")\n",
    "\n",
    "# Write the combined dataframe to a new CSV file\n",
    "combined_df.to_csv(f'{output_directory}{date}_network_aggregated.csv', index=True, sep=';')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
