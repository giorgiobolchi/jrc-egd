{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define directories\n",
    "\n",
    "# Define the project root directory\n",
    "root_dir = '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/'\n",
    "\n",
    "# File paths\n",
    "report1_dir = '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/report1.pdf'\n",
    "report1_annex_dir = '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/report1_annex.pdf'\n",
    "target_data_dir = '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/XLSX_target_data_v1.2_LLM.csv'\n",
    "\n",
    "# LLM parameters\n",
    "chunks = 10\n",
    "seed = None \n",
    "temperature = 0.2\n",
    "model = \"llama-3.3-70b-instruct\"  # or \"gpt-4o\"\n",
    "date= '0227' # to indicate date in filenames\n",
    "output_dir = f'/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/Outputs/{date}/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTIONS\n",
    "\n",
    "sys.path.insert(0, root_dir) # Add the project root directory to the system path\n",
    "\n",
    "from API import get_chat_response, num_tokens_from_string # Import the API functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data\n",
    "\n",
    "# Import all target data (target_code + target_content)\n",
    "target_data = pd.read_csv(target_data_dir, sep=\";\") # note: the separator is a semicolon (;) and not a comma (,)\n",
    "\n",
    "\n",
    "# Load NACE data\n",
    "from Data.NACEdata import NACElevel1, NACElevel2, NACElevel3\n",
    "\n",
    "\n",
    "# Import report1 and report1_annexes as pdf and convert to plain text\n",
    "\n",
    "with pdfplumber.open(report1_dir) as pdf:\n",
    "    # Extract the text from the PDF\n",
    "    report1 = \"\"\n",
    "    for page in pdf.pages:\n",
    "        report1 += page.extract_text()\n",
    "\n",
    "with pdfplumber.open(report1_annex_dir) as pdf:\n",
    "    # Extract the text from the PDF\n",
    "    report1_annex = \"\"\n",
    "    for page in pdf.pages:\n",
    "        report1_annex += page.extract_text()\n",
    "\n",
    "# Preprocess the text\n",
    "report1 = report1.strip()  # Remove leading and trailing whitespaces\n",
    "report1 = report1.replace(\"\\n\", \" \") # Replace new lines with spaces\n",
    "report1 = report1.replace(\"\\t\", \" \") # Replace tabs with spaces\n",
    "\n",
    "report1_annex = report1_annex.strip()\n",
    "report1_annex = report1_annex.replace(\"\\n\", \" \")\n",
    "report1_annex = report1_annex.replace(\"\\t\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE ANSWERS\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "chunks = chunks\n",
    "seed = seed \n",
    "temperature = temperature\n",
    "model = model\n",
    "date= date\n",
    "output_dir = output_dir\n",
    "\n",
    "\n",
    "\n",
    "# (Loop tools)\n",
    "answers_content = [] # create empty list that will store the answers content\n",
    "answers_metadata = pd.DataFrame(columns=[\"chunk\",       # create empty panda dataframe with the following columns so to gather a bit more data on the responses and ultimately try to assess consistency\n",
    "                                         \"replicate\",\n",
    "                                         \"model\",\n",
    "                                         \"seed\",\n",
    "                                         \"temperature\",\n",
    "                                         \"system_fingerprint\", \n",
    "                                         \"prompt_tokens\", \n",
    "                                         \"completion_tokens\"])  \n",
    "\n",
    "targets_chunks = np.array_split(ary=target_data, indices_or_sections=chunks) # splits the target_data into chunks\n",
    "\n",
    "\n",
    "# Loop\n",
    "\n",
    "for x in range(len(targets_chunks)):\n",
    "\n",
    "    # Subset per chunk to avoid overloading the model\n",
    "    targets_subset = targets_chunks[x] # run the request for chunk n°'x'\n",
    "    targets_list = [f\"{row['target_code']}: {row['target_content']}\" for index, row in targets_subset.iterrows()] # Concatenate target_code and target_content into a list so that it can be added to the prompt as text\n",
    "\n",
    "    \n",
    "    # Define request\n",
    "    prompt = f'''Hello,\n",
    "\n",
    "            Data input & Context:\n",
    "            - NACE classification categories:  {NACElevel1} + {NACElevel2} + {NACElevel3}.\n",
    "            - List of targets: {targets_list}.\n",
    "            - Report n°1 about \"DELIVERING THE EU GREEN DEAL Progress towards targets (2025)\": {report1}\n",
    "            \n",
    "            \n",
    "            Task: \n",
    "            - In the context of report n°1, for each target, analyse its content description and assign to each target a NACE category for each level (1,2,3). \n",
    "\n",
    "            Answer format: provide your answer as a table in csv format please (separator: \";\"), with the following columns:\n",
    "            - target_code (e.g., TA1.9)\n",
    "            - target_content (e.g., The contribution of the sectors covered by the EU ETS with respect to the EU Climate ambition should be of -62 % compared to 2005 (increasing the linear emissions reduction factor from 2.2 % per year up to 4.4 %)) \n",
    "            - NACE_level1 (e.g., D - Electricity, Gas, Steam and Air Conditioning Supply)\n",
    "            - NACE_level1_extra1 (e.g.if other categories overlap)\n",
    "            - NACE_level1_extra2 (e.g.if other categories overlap)\n",
    "            - NACE_level2 (e.g., D35 - Electricity, gas, steam and air conditioning supply)\n",
    "            - NACE_level2_extra1 (e.g.if other categories overlap)\n",
    "            - NACE_level2_extra2 (e.g.if other categories overlap)\n",
    "            - NACE_level_3 (e.g., D35.1 - Electric power generation, transmission and distribution)\n",
    "            - NACE_level_3_extra1 (e.g.if other categories overlap)\n",
    "            - NACE level3_extra2 (e.g.if other categories overlap)\n",
    "            - justification\n",
    "            - confidence_score (e.g. confidence value from 0 to 10 about the assignation choices that are made)\n",
    "\n",
    "            Specifications:\n",
    "            - If there is some overlap, add the multiple possible fitting NACE categories (up to maximum 3 per NACE level). \n",
    "            - Include the name of the NACE categories.\n",
    "            - Don't forget to provide the title of the target. \n",
    "            - If there is no target content, do not invent new content, just state it as empty.\n",
    "            - For each target, write one to two sentences justifying your choice.\n",
    "            - Output only the csv table and no additional commentary text.\n",
    "\n",
    "            Thank you.'''\n",
    "\n",
    "\n",
    "    # Print to double check amount of tokens in prompt (JRC llama have a max of 120k)\n",
    "    tokens_per_chunk = f'''Chunk:{x+1}/{len(targets_chunks)} \\nTargets per chunk: {len(targets_chunks[x])} \\nPrompt length: {len(prompt)} \\nPrompt tokens (o200k_base encoding): {num_tokens_from_string(prompt, \"o200k_base\")} \\nPrompt tokens (cl100k_base encoding): {num_tokens_from_string(prompt, \"cl100k_base\")} \\n'''\n",
    "    print(tokens_per_chunk)\n",
    "\n",
    "    # Generate answer\n",
    "    answer= get_chat_response(prompt=prompt,\n",
    "                              seed=seed,\n",
    "                              model=model,\n",
    "                              temperature=temperature  # The temperature parameter influences the randomness of the generated responses. A higher value, such as 0.8, makes the answers more diverse, while a lower value, like 0.2, makes them more focused and deterministic.\n",
    "                              )\n",
    "\n",
    "    answers_content.append((f'chunk{x+1}', answer['response_content'])) # add the different replicats for answers over a single TA in a same list so i can analyse the similarity later\n",
    "    answers_metadata.loc[x] = (f'chunk{x+1}', #TA code\n",
    "                               f'', # replicate nbr\n",
    "                               model,  \n",
    "                               seed, \n",
    "                               temperature, \n",
    "                               answer[\"system_fingerprint\"],\n",
    "                               answer[\"prompt_tokens\"],\n",
    "                               answer[\"completion_tokens\"]\n",
    "                               ) \n",
    "    \n",
    "\n",
    "    \n",
    "    # Save response as csv file\n",
    "    output_name = f'{date}output_chk{x+1}_s{seed}_t{temperature}.csv'     # -> to split by chunks\n",
    "\n",
    "    with open((os.path.join(output_dir, output_name)), 'w') as f:\n",
    "         f.write(answer[\"response_content\"])\n",
    "\n",
    "\n",
    "# Save triplicats metadata as csv\n",
    "answers_metadata.to_csv(path_or_buf= f'{output_dir}{date}output_chk{len(targets_chunks)}_s{seed}_t{temperature}_metadata.csv', sep=';', index=False)  # split by chunks method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional block)\n",
    "\n",
    "text_file = open(\"prompt.txt\", \"w\") # save the prompt as a text file to view it in its entirety an double check its content.\n",
    "n = text_file.write(prompt) \n",
    "\n",
    "# Close file\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
