{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIBRARIES\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import pdfplumber\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "# Define absolute python path\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM') \n",
    "\n",
    "## FUNCTIONS\n",
    "\n",
    "# Load API and import request function\n",
    "from Code.API import get_chat_response, test_function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## DATA\n",
    "\n",
    "# Load NACE data\n",
    "from Data.NACEdata import NACElevel0, NACElevel1, NACElevel2, NACElevel3     \n",
    "\n",
    "# Import all target data (target_code + target_content)\n",
    "targets_pd = pd.read_csv('/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/XLSX_target_data_v1.2_LLM.csv', sep=\";\")\n",
    "\n",
    "# Import report1 and report1_annexes as pdf and covnert to plain text\n",
    "\n",
    "with pdfplumber.open('/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/report1.pdf') as pdf:\n",
    "    # Extract the text from the PDF\n",
    "    report1 = \"\"\n",
    "    for page in pdf.pages:\n",
    "        report1 += page.extract_text()\n",
    "\n",
    "with pdfplumber.open('/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/report1_annex.pdf') as pdf:\n",
    "    # Extract the text from the PDF\n",
    "    report1_annex = \"\"\n",
    "    for page in pdf.pages:\n",
    "        report1_annex += page.extract_text()\n",
    "\n",
    "    # Preprocess the text\n",
    "report1 = report1.strip()\n",
    "report1 = report1.replace(\"\\n\", \" \")\n",
    "report1 = report1.replace(\"\\t\", \" \")\n",
    "\n",
    "report1_annex = report1_annex.strip()\n",
    "report1_annex = report1_annex.replace(\"\\n\", \" \")\n",
    "report1_annex = report1_annex.replace(\"\\t\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE ANSWERS\n",
    "\n",
    "\n",
    "# Select data to loop through\n",
    "\n",
    "\n",
    "# TA = (['TA1','TA1','TA1',   # n=3xTA\n",
    "#        'TA2','TA2','TA2',\n",
    "#        'TA3','TA3','TA3',\n",
    "#        'TA4','TA4','TA4',\n",
    "#        'TA5','TA5','TA5',\n",
    "#        'TA6','TA6','TA6',\n",
    "#        'TA7','TA7','TA7',]) \n",
    "#TA = ['TA1','TA1','TA1'] # if want to test on only TA (smaller subset to go faster)\n",
    "#TA = ['TA1','TA2','TA3','TA4','TA5','TA6','TA7'] # n= 1xTA\n",
    "TA = ['TA1'] # n=1xTA1\n",
    "\n",
    "# Model parameters\n",
    "seed = None \n",
    "temperature = 0.2\n",
    "model = \"gpt-4o\"  #or \"llama-3.3-70b-instruct\"\n",
    "\n",
    "\n",
    "date= '0210' # to indicate date in filenames\n",
    "output_directory = f'/Users/giorgiobolchi2/Documents/GitHub/jrc-egd/LLM/Data/Outputs/{date}/'\n",
    "\n",
    "\n",
    "# (Loop tools)\n",
    "loop_counter = 0\n",
    "answers_content = []\n",
    "answers_metadata = pd.DataFrame(columns=[\"TA\",\n",
    "                                         \"replicate\",\n",
    "                                         \"seed\",\n",
    "                                         \"temperature\",\n",
    "                                         \"system_fingerprint\", \n",
    "                                         \"prompt_tokens\", \n",
    "                                         \"completion_tokens\"])  # create empty panda dataframe with the following columns so to gather a bit more data on the responses and ultimately try to assess consistency\n",
    "\n",
    "# Loop\n",
    "for x in range(len(TA)):\n",
    "\n",
    "    # Subset data to avoid overloading the GPT\n",
    "    target_subset = targets_pd[targets_pd['target_code'].str.contains(TA[x])]  # subset rows containing one of the characters in  TA[] (ie, select only a specific TA and its targets, because selecting everything in one go is too big for the AI to process)                                                                                                                                          # eg: TA[0] = 'TA1'\n",
    "    target_list = [f\"{row['target_code']}: {row['target_content']}\" for index, row in target_subset.iterrows()] # Concatenate target_code and target_content into a list so that it can be added to the prompt as text\n",
    "    \n",
    "    \n",
    "    # Define request\n",
    "    prompt = f'''Hello,\n",
    "\n",
    "            Data input: please get acquainted with the following data:\n",
    "            - NACE classification categories:  {NACElevel1} + {NACElevel2} + {NACElevel3}.\n",
    "            - List of targets: {target_list}.\n",
    "            - Report n°1 about \"DELIVERING THE EU GREEN DEAL Progress towards targets (2025)\": {report1} + {report1_annex}\n",
    "            \n",
    "            Task: \n",
    "            - In the context of report n°1, for each target, analyse its content description and assign to each target a NACE category for each level (1,2,3). \n",
    "\n",
    "            Answer format: provide your answer as a table in csv format please (separator: \";\"), with the following columns:\n",
    "            - target_code (e.g., TA1.9)\n",
    "            - target_content (e.g., The contribution of the sectors covered by the EU ETS with respect to the EU Climate ambition should be of -62 % compared to 2005 (increasing the linear emissions reduction factor from 2.2 % per year up to 4.4 %)) \n",
    "            - NACE_level1 (e.g., D - Electricity, Gas, Steam and Air Conditioning Supply)\n",
    "            - NACE_level1_extra1 (e.g.if other categories overlap)\n",
    "            - NACE_level1_extra2 (e.g.if other categories overlap)\n",
    "            - NACE_level2 (e.g., D35 - Electricity, gas, steam and air conditioning supply)\n",
    "            - NACE_level2_extra1 (e.g.if other categories overlap)\n",
    "            - NACE_level2_extra2 (e.g.if other categories overlap)\n",
    "            - NACE_level_3 (e.g., D35.1 - Electric power generation, transmission and distribution)\n",
    "            - NACE_level_3_extra1 (e.g.if other categories overlap)\n",
    "            - NACE level3_extra2 (e.g.if other categories overlap)\n",
    "            - justification\n",
    "            - confidence_score (e.g. confidence value from 0 to 10 about the assignation choices that are made)\n",
    "\n",
    "            Specifications:\n",
    "            - If there is some overlap, add the multiple possible fitting NACE categories (up to maximum 3 per NACE level). \n",
    "            - Include the name of the NACE categories.\n",
    "            - Don't forget to provide the title of the target. \n",
    "            - If there is no target content, do not invent new content, just state it as empty.\n",
    "            - For each target, write one to two sentences justifying your choice.\n",
    "            - Output only the csv table and no additional commentary text.\n",
    "\n",
    "            Thank you.'''\n",
    "\n",
    "    # Generate answer\n",
    "    answer= get_chat_response(prompt=prompt,\n",
    "                              seed=seed,\n",
    "                              model=model,\n",
    "                              temperature=temperature  # The temperature parameter influences the randomness of the generated responses. A higher value, such as 0.8, makes the answers more diverse, while a lower value, like 0.2, makes them more focused and deterministic.\n",
    "                              )\n",
    "\n",
    "    answers_content.append((f'{TA[x]}.{loop_counter+1}', answer['response_content'])) # add the different replicats for answers over a single TA in a same list so i can analyse the similarity later\n",
    "    answers_metadata.loc[x] = (f'{TA[x]}', #TA code\n",
    "                               f'{loop_counter+1}', # replicate nbr\n",
    "                               seed, \n",
    "                               temperature, \n",
    "                               answer[\"system_fingerprint\"],\n",
    "                               answer[\"prompt_tokens\"],\n",
    "                               answer[\"completion_tokens\"]\n",
    "                               ) \n",
    "    \n",
    "    # Save response as csv file\n",
    "    output_name = f'{date}output_{TA[x]}.{loop_counter+1}_s{seed}_t{temperature}.csv'\n",
    "\n",
    "    with open((os.path.join(output_directory, output_name)), 'w') as f:\n",
    "         f.write(answer[\"response_content\"])\n",
    "\n",
    "    # (Extra loop tools)\n",
    "    loop_counter += 1         # incremental loop counter that resets to 0 every 3 loops so that it can add the \".1,2,3\" at the end of each triplicats file names\n",
    "    if loop_counter % 3 == 0:\n",
    "        loop_counter = 0\n",
    "\n",
    "\n",
    "# Save triplicats metadata as csv\n",
    "answers_metadata.to_csv(path_or_buf= f'/Users/giorgiobolchi2/Documents/JRC/LLM/Data/Outputs/{date}/{date}output_s{seed}_t{temperature}_metadata.csv', \n",
    "                        sep=';', \n",
    "                        index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE TO CLEAN CSV FILES from first and last rows\n",
    "output_directory = f'/Users/giorgiobolchi2/Documents/JRC/LLM/Data/Outputs/{date}'\n",
    "output_directory = output_directory\n",
    "\n",
    "for filename in os.listdir(output_directory):\n",
    "\n",
    "    if 'TA' in filename and '.csv' in filename:     # Check if the file name contains the characters 'TA'\n",
    "        \n",
    "        # Open the file for reading and writing\n",
    "        with open(f'{output_directory}{filename}', 'r+') as file:  # r+ = mode to open the file for both reading and writing\n",
    "            lines = file.readlines()\n",
    "            lines = lines[1:-1] # remove first and last row\n",
    "            file.seek(0)  # move the file pointer to the beginning\n",
    "            file.writelines(lines) # write the modified lines back to the file.\n",
    "            file.truncate() # set the length of the file to the current position of the file pointer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEMP\n",
    "\n",
    "seed = None \n",
    "temperature = 0.2\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "date= '0131' \n",
    "output_directory = f'/Users/giorgiobolchi2/Documents/JRC/LLM/Data/Outputs/{date}/trial_1/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAFRAME COMPARISON SANDBOX\n",
    "\n",
    "\n",
    "# Important note: you need to clean the generated csv files manually before running this following code block: \n",
    "#                 - if previous cleaning loop didn't work (it should work) -> remove the first line containing the characters ```csv and the last line with ```\n",
    "#                 - it can happen that some columns (especially justifications and confidence_scores) are moved one cell to the right or left, move them back in the right place\n",
    "\n",
    "\n",
    "date= date\n",
    "seed= seed\n",
    "temperature = temperature\n",
    "output_directory = output_directory\n",
    "\n",
    "\n",
    "#TA = ['TA1','TA2','TA3','TA4','TA5','TA6','TA7']\n",
    "TA = ['TA5']\n",
    "\n",
    "for x in range(len(TA)):\n",
    "\n",
    "    # Define temporary dataframes for respective TA replicates \n",
    "    df1 = pd.read_csv(f'{output_directory}{date}output_{TA[x]}.1_s{seed}_t{temperature}.csv', sep=\";\")\n",
    "    df2 = pd.read_csv(f'{output_directory}{date}output_{TA[x]}.2_s{seed}_t{temperature}.csv', sep=\";\")\n",
    "    df3 = pd.read_csv(f'{output_directory}{date}output_{TA[x]}.3_s{seed}_t{temperature}.csv', sep=\";\")\n",
    "\n",
    "\n",
    "    # Create a list of these DataFrames\n",
    "    dfs = [df1, df2, df3]\n",
    "\n",
    "    # Create a list to store the comparison tables\n",
    "    comparisons = []\n",
    "\n",
    "    # Compare replicats dataframes:\n",
    "    for i in range(len(dfs)):\n",
    "        for j in range(i+1, len(dfs)):\n",
    "            comparison = dfs[i].reset_index(drop=True).eq(dfs[j].reset_index(drop=True)) # Reset the index before comparing (make it easier to compare)\n",
    "            comparisons.append(comparison) # Add the comparison table to the list\n",
    "\n",
    "    # Concatenate the comparison tables into a single DataFrame\n",
    "    df_comparisons = pd.concat(comparisons, ignore_index=True)\n",
    "\n",
    "    # Get information on the distribution of NA values per columns per replicat\n",
    "    df_na = pd.DataFrame({f'{TA[x]}.1': df1.isna().sum(), \n",
    "                          f'{TA[x]}.2': df2.isna().sum(), \n",
    "                          f'{TA[x]}.3': df3.isna().sum()})\n",
    "    \n",
    "# Save results as csv\n",
    "    output_directory = output_directory\n",
    "    # Comparisons\n",
    "    df_comparisons.to_csv(f'{output_directory}{date}comparisons_{TA[x]}.csv', sep=';', index=False)\n",
    "    # NA distributions\n",
    "    df_na.to_csv(f'{output_directory}{date}NAdistribution_{TA[x]}.csv', sep=';', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df2['NACE_level1'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
